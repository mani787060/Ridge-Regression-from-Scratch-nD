# Ridge Regression from Scratch for n-Dimensional Data

-> This project implements **Ridge Regression** from scratch for **multi-dimensional (n-D) datasets** without using built-in machine learning libraries. It demonstrates how regularization        helps control model complexity and reduce overfitting when handling high-dimensional inputs.

## Key Concepts Covered:-
-> Ridge Regression Cost Function (L2 Regularization)
-> Gradient Descent for n-D Feature Space
-> Computing gradients for both weights & bias
-> Effect of Î» (alpha) on coefficients
-> Comparison with Linear Regression behavior

## What This Notebook Includes:-
-> Synthetic & real dataset experiments  
-> Manual implementation of the full algorithm  
-> Visualization of coefficient shrinkage  
-> Explanation of each step in gradient updates  

## Objective:-
-> Understanding how regularization stabilizes learning and improves generalization in models with many features.
